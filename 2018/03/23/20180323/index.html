<!DOCTYPE html><html lang="zh-Hans"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>python学习笔记（二） | 高荣登</title><link rel="stylesheet" type="text/css" href="//fonts.neworld.org/css?family=Source+Code+Pro"><link rel="stylesheet" type="text/css" href="/css/style.css?v=2.0.1"><link rel="stylesheet" type="text/css" href="/css/highlight.css?v=2.0.1"><link rel="Shortcut Icon" href="/favicon.ico"><link rel="bookmark" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">python学习笔记（二）</h1><a id="logo" href="/.">高荣登</a><p class="description"></p></div><div id="nav-menu"><a href="/." class="current"><i class="fa fa-home"> Start</i></a><a href="/archives/"><i class="fa fa-archive"> Archiv</i></a><a href="/about/"><i class="fa fa-user"> Über</i></a></div><div id="search-form"><div id="result-mask" class="hide"></div><label><input id="search-key" type="text" autocomplete="off" placeholder="Arama"></label><div id="result-wrap" class="hide"><div id="search-result"></div></div><div class="hide"><template id="search-tpl"><div class="item"><a href="/{path}" title="{title}"><div class="title">{title}</div><div class="time">{date}</div><div class="tags">{tags}</div></a></div></template></div></div></div><div id="layout" class="layout-g"><div class="layout-l"><div class="content_container"><div class="post"><h1 class="post-title">python学习笔记（二）</h1><div class="post-meta"><a href="/2018/03/23/20180323/#comments" class="comment-count"></a><p><span class="date">Mar 23, 2018</span><span><i id="busuanzi_container_page_pv"><i id="busuanzi_value_page_pv"></i><i>Schlägt</i></i></span></p></div><div class="post-content"><h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=3362774969,183177314&amp;fm=27&amp;gp=0.jpg" alt=""></h2><h4 id="今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。"><a href="#今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。" class="headerlink" title="今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。"></a>今天我要爬取<a href="http://www.weather.com.cn/textFC/hb.shtml" target="_blank" rel="noopener">中国天气网</a>的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。</h4><hr>
<p>#####首先，我们来看一下我们要爬取的目标网站，做一些准备工作。PS:本地图片现在还不会上传到markdown,很难受。</p>
<h5 id="第一步-，我们需要以下几个信息"><a href="#第一步-，我们需要以下几个信息" class="headerlink" title="第一步 ，我们需要以下几个信息"></a>第一步 ，我们需要以下几个信息</h5><p>1.得到目标网站：</p>
<p><pre><br>root_url =  “<a href="http://www.weather.com.cn/textFC/hb.shtml&quot;" target="_blank" rel="noopener">http://www.weather.com.cn/textFC/hb.shtml&quot;</a><br></pre><br>2.得到我们浏览器的请求头：</p>
<p><pre><br>m_headers = {<br>        “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36”}<br></pre></p>
<h4 id="第二步-，现在我们开始写代码"><a href="#第二步-，现在我们开始写代码" class="headerlink" title="第二步 ，现在我们开始写代码"></a>第二步 ，现在我们开始写代码</h4><p>1.请求网站</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">req = urllib.request.Request(url=url, headers=m_headers)</span><br></pre></td></tr></table></figure>
<p>2.下载网页源码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res = urllib.request.urlopen(req)</span><br><span class="line">data = res.read()</span><br><span class="line"># 确定编码格式 utf-8</span><br><span class="line">data = data.decode(&apos;utf-8&apos;)</span><br></pre></td></tr></table></figure></p>
<p>3.进行网页解析<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 网页解析</span><br><span class="line">soup = BeautifulSoup(data, &apos;html.parser&apos;)</span><br></pre></td></tr></table></figure></p>
<p>4.通过查询网站源码，F12+…..确定所需要数据在的盒子。<br>注意：这里返回的是一个数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查找里面的带有conMidtab2 的div</span><br><span class="line">conMid_list = soup.find_all(&apos;div&apos;, class_=&apos;conMidtab2&apos;)</span><br></pre></td></tr></table></figure></p>
<p>5.遍历这个数组，找到我们需要信息所在的行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 遍历数组查找class_=&apos;conMidtab2&apos;下面的数据</span><br><span class="line">   for x in conMid_list:</span><br><span class="line">       tr_list = x.find_all(&apos;tr&apos;)[2:]  # 使用切片获取第2个数据之后的数据</span><br><span class="line">       province = &quot;&quot;</span><br><span class="line">       # min_tempature = 0</span><br><span class="line">       # max_tempature = 0</span><br><span class="line">       for index, tr in enumerate(tr_list):</span><br><span class="line">           if index == 0:</span><br><span class="line">               td_list = tr.find_all(&apos;td&apos;)</span><br><span class="line">               province = td_list[0].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               city = td_list[1].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               max_tempature = td_list[4].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               min_tempature = td_list[7].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">           else:</span><br><span class="line">               td_list = tr.find_all(&apos;td&apos;)</span><br><span class="line">               city = td_list[0].text.replace(&apos;\n&apos;, &apos;&apos;)</span><br><span class="line">               min_tempature = td_list[6].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               max_tempature = td_list[3].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br></pre></td></tr></table></figure></p>
<p>6.创建字典用来存储，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 先在上面全局声明</span><br><span class="line">TEMPATURE_LIST = []</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line"># 遍历数组之后，我们在把需要的数据存到字典里面</span><br><span class="line"># 将需要的信息添加到字典</span><br><span class="line">            TEMPATURE_LIST.append(&#123;</span><br><span class="line">                &apos;city&apos;:province + city,</span><br><span class="line">                &apos;min_tempature&apos;: min_tempature,</span><br><span class="line">                &apos;max_tempature&apos;: max_tempature</span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure></p>
<p>7.封装成函数，参数为url<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def get_temperature(url):</span><br></pre></td></tr></table></figure></p>
<p>8.水到渠成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    urls = [&apos;http://www.weather.com.cn/textFC/hb.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/db.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hd.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hz.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hn.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/xb.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/xn.shtml&apos;]</span><br><span class="line">    for url in urls:</span><br><span class="line">        get_temperature(url)</span><br><span class="line">        # 睡眠两秒 职业道德</span><br><span class="line">        time.sleep(2)</span><br></pre></td></tr></table></figure></p>
<p>9.将数据写到json文件里面<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> # 将得到的数据写成json格式</span><br><span class="line">line = json.dumps(TEMPATURE_LIST,ensure_ascii=False)</span><br><span class="line">with open(&apos;temp.json&apos;,&apos;w&apos;) as fp:</span><br><span class="line">    fp.write(line)</span><br></pre></td></tr></table></figure></p>
<p>10.总结，难点在于寻找所需要信息在的行，并进行提取。顺便说一下，这里需要引入的库。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import json</span><br><span class="line">import urllib.request</span><br><span class="line">from bs4 import BeautifulSoup</span><br></pre></td></tr></table></figure></p>
<p>11.这样一运行你就可以得到数据啦。如果有什么疑问的话，可以加我的QQ：2914129301，我也是刚学习python,对爬虫很感兴趣，欢迎交流。</p>
</div><div class="tags"></div><div class="post-share"><div class="bdsharebuttonbox"><span style="float:left;line-height: 28px;height: 28px;font-size:16px;font-weight:blod">分享到：</span><a href="#" data-cmd="more" class="bds_more"></a><a href="#" data-cmd="mshare" title="分享到一键分享" class="bds_mshare"></a><a href="#" data-cmd="fbook" title="分享到Facebook" class="bds_fbook"></a><a href="#" data-cmd="twi" title="分享到Twitter" class="bds_twi"></a><a href="#" data-cmd="linkedin" title="分享到linkedin" class="bds_linkedin"></a><a href="#" data-cmd="youdao" title="分享到有道云笔记" class="bds_youdao"></a><a href="#" data-cmd="evernotecn" title="分享到印象笔记" class="bds_evernotecn"></a><a href="#" data-cmd="weixin" title="分享到微信" class="bds_weixin"></a><a href="#" data-cmd="qzone" title="分享到QQ空间" class="bds_qzone"></a><a href="#" data-cmd="tsina" title="分享到新浪微博" class="bds_tsina"></a></div></div><div class="post-nav"><a href="/2018/03/28/tags/" class="pre">tags</a><a href="/2018/03/20/20180320/" class="next">python学习笔记（一）</a></div><div id="comments"></div></div></div></div><div class="layout-r"><div id="sidebar"><div class="search-pla"></div><div id="toc" class="widget"><div class="widget-title"><i class="fa fa-fei">Inhalte</i></div><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#"><span class="toc-text"></span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。"><span class="toc-text">今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#第一步-，我们需要以下几个信息"><span class="toc-text">第一步 ，我们需要以下几个信息</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#第二步-，现在我们开始写代码"><span class="toc-text">第二步 ，现在我们开始写代码</span></a></li></ol></li></ol></li></ol></div><div class="widget"><div class="widget-title"><i class="fa fa-xie"> Letzte</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/03/28/tags/">tags</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/23/20180323/">python学习笔记（二）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/20/20180320/">python学习笔记（一）</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/12/20180312/">常用的网站</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/03/05/20180305/">欢迎来到我的博客</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-biao"> Tags</i></div><div class="tagcloud"><a href="/tags/tags/" style="font-size: 15px;">tags</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-archive"> Archiv</i></div><ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-you"> Blogroll</i></div><ul></ul><a href="http://www.example1.com/" title="site-name1" target="_blank">site-name1</a><ul></ul><a href="http://www.example2.com/" title="site-name2" target="_blank">site-name2</a><ul></ul><a href="http://www.example3.com/" title="site-name3" target="_blank">site-name3</a></div></div></div></div><a id="totop" href="#top"></a><div id="footer"><div class="footer-info"><p><a href="/baidusitemap.xml">Baidu Site Haritası</a> |  <a href="/atom.xml">RSS</a> |  <a href="/about/">Über</a></p><p>本站总访问量：<i id="busuanzi_container_site_pv"><i id="busuanzi_value_site_pv"></i></i>次</p><p><span> Copyright &copy;<a href="/." rel="nofollow">高荣登.</a></span><span> Theme by<a rel="nofollow" target="_blank" href="https://github.com/chaooo/hexo-theme-BlueLake"> BlueLake.</a></span><span> Count by<a href="http://busuanzi.ibruce.info/"> busuanzi.</a></span><span> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a></span></p></div></div></div><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><script type="text/javascript" src="/js/search.json.js?v=2.0.1"></script><script type="text/javascript" src="/js/toctotop.js?v=2.0.1" async></script><script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdMiniList":["mshare","weixin","tsina","qzone","linkedin","fbook","twi","print","renren","sqq","evernotecn","bdysc","tqq","tqf","bdxc","kaixin001","tieba","douban","bdhome","thx","ibaidu","meilishuo","mogujie","diandian","huaban","duitang","hx","fx","youdao","sdo","qingbiji","people","xinhua","mail","isohu","yaolan","wealink","ty","iguba","h163","copy"],"bdPic":"","bdStyle":"1","bdSize":"16"},"share":{},"image":{"viewList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["tsina","qzone","weixin","fbook","twi","linkedin","youdao","evernotecn","mshare"]}};with(document)0[(getElementsByTagName('head')[0]||head).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
</script></body></html>