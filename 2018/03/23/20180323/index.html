<!DOCTYPE html>
<html>

<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8" >
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <title>python学习笔记（二） | Andy</title>
  <meta name="description" content="" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="MobileOptimized" content="320" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />

  <link rel="stylesheet" type="text/css" href="/css/screen.css" />
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Noto+Serif:400,700,400italic|Open+Sans:700,400" />

  <meta name="generator" content="Andy">

  
  
  

  
</head>


<body class="post-template">

  <header class="site-head"  style="background-image: url(//blog.ghost.org/content/images/2013/Nov/cover.png)" >
    <div class="vertical">
        <div class="site-head-content inner">
             <a class="blog-logo" href="/"><img src="//blog.ghost.org/content/images/2013/Nov/bloglogo_1-1.png" alt="Blog Logo"/></a> 
            <h1 class="blog-title">Andy</h1>
            <h2 class="blog-description"></h2>
        </div>
    </div>
</header>
  

<main class="content" role="main">
  <article class="post">
    <span class="post-meta">
      <time datetime="2018-03-23T08:02:57.027Z" itemprop="datePublished">
          2018-03-23
      </time>
    
</span>
    <h1 class="post-title">python学习笔记（二）</h1>
    <section class="post-content">
      <h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=3362774969,183177314&amp;fm=27&amp;gp=0.jpg" alt=""></h2><h4 id="今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。"><a href="#今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。" class="headerlink" title="今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。"></a>今天我要爬取<a href="http://www.weather.com.cn/textFC/hb.shtml" target="_blank" rel="noopener">中国天气网</a>的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。</h4><hr>
<p>#####首先，我们来看一下我们要爬取的目标网站，做一些准备工作。PS:本地图片现在还不会上传到markdown,很难受。</p>
<h5 id="第一步-，我们需要以下几个信息"><a href="#第一步-，我们需要以下几个信息" class="headerlink" title="第一步 ，我们需要以下几个信息"></a>第一步 ，我们需要以下几个信息</h5><p>1.得到目标网站：</p>
<p><pre><br>root_url =  “<a href="http://www.weather.com.cn/textFC/hb.shtml&quot;" target="_blank" rel="noopener">http://www.weather.com.cn/textFC/hb.shtml&quot;</a><br></pre><br>2.得到我们浏览器的请求头：</p>
<p><pre><br>m_headers = {<br>        “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36”}<br></pre></p>
<h4 id="第二步-，现在我们开始写代码"><a href="#第二步-，现在我们开始写代码" class="headerlink" title="第二步 ，现在我们开始写代码"></a>第二步 ，现在我们开始写代码</h4><p>1.请求网站</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">req = urllib.request.Request(url=url, headers=m_headers)</span><br></pre></td></tr></table></figure>
<p>2.下载网页源码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res = urllib.request.urlopen(req)</span><br><span class="line">data = res.read()</span><br><span class="line"># 确定编码格式 utf-8</span><br><span class="line">data = data.decode(&apos;utf-8&apos;)</span><br></pre></td></tr></table></figure></p>
<p>3.进行网页解析<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 网页解析</span><br><span class="line">soup = BeautifulSoup(data, &apos;html.parser&apos;)</span><br></pre></td></tr></table></figure></p>
<p>4.通过查询网站源码，F12+…..确定所需要数据在的盒子。<br>注意：这里返回的是一个数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查找里面的带有conMidtab2 的div</span><br><span class="line">conMid_list = soup.find_all(&apos;div&apos;, class_=&apos;conMidtab2&apos;)</span><br></pre></td></tr></table></figure></p>
<p>5.遍历这个数组，找到我们需要信息所在的行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 遍历数组查找class_=&apos;conMidtab2&apos;下面的数据</span><br><span class="line">   for x in conMid_list:</span><br><span class="line">       tr_list = x.find_all(&apos;tr&apos;)[2:]  # 使用切片获取第2个数据之后的数据</span><br><span class="line">       province = &quot;&quot;</span><br><span class="line">       # min_tempature = 0</span><br><span class="line">       # max_tempature = 0</span><br><span class="line">       for index, tr in enumerate(tr_list):</span><br><span class="line">           if index == 0:</span><br><span class="line">               td_list = tr.find_all(&apos;td&apos;)</span><br><span class="line">               province = td_list[0].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               city = td_list[1].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               max_tempature = td_list[4].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               min_tempature = td_list[7].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">           else:</span><br><span class="line">               td_list = tr.find_all(&apos;td&apos;)</span><br><span class="line">               city = td_list[0].text.replace(&apos;\n&apos;, &apos;&apos;)</span><br><span class="line">               min_tempature = td_list[6].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               max_tempature = td_list[3].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br></pre></td></tr></table></figure></p>
<p>6.创建字典用来存储，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 先在上面全局声明</span><br><span class="line">TEMPATURE_LIST = []</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line"># 遍历数组之后，我们在把需要的数据存到字典里面</span><br><span class="line"># 将需要的信息添加到字典</span><br><span class="line">            TEMPATURE_LIST.append(&#123;</span><br><span class="line">                &apos;city&apos;:province + city,</span><br><span class="line">                &apos;min_tempature&apos;: min_tempature,</span><br><span class="line">                &apos;max_tempature&apos;: max_tempature</span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure></p>
<p>7.封装成函数，参数为url<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def get_temperature(url):</span><br></pre></td></tr></table></figure></p>
<p>8.水到渠成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    urls = [&apos;http://www.weather.com.cn/textFC/hb.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/db.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hd.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hz.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hn.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/xb.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/xn.shtml&apos;]</span><br><span class="line">    for url in urls:</span><br><span class="line">        get_temperature(url)</span><br><span class="line">        # 睡眠两秒 职业道德</span><br><span class="line">        time.sleep(2)</span><br></pre></td></tr></table></figure></p>
<p>9.将数据写到json文件里面<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> # 将得到的数据写成json格式</span><br><span class="line">line = json.dumps(TEMPATURE_LIST,ensure_ascii=False)</span><br><span class="line">with open(&apos;temp.json&apos;,&apos;w&apos;) as fp:</span><br><span class="line">    fp.write(line)</span><br></pre></td></tr></table></figure></p>
<p>10.总结，难点在于寻找所需要信息在的行，并进行提取。顺便说一下，这里需要引入的库。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import json</span><br><span class="line">import urllib.request</span><br><span class="line">from bs4 import BeautifulSoup</span><br></pre></td></tr></table></figure></p>
<p>11.这样一运行你就可以得到数据啦。如果有什么疑问的话，可以加我的QQ：2914129301，我也是刚学习python,对爬虫很感兴趣，欢迎交流。</p>

    </section>
    <footer class="post-footer">
      <section class="author">
    <h4>Andy</h4>
    <p>一个热爱生活，喜欢运动的90后男青年。</p>
</section>
      <section class="share">
    <h4>Share this post</h4>
    <a class="icon-twitter" href="http://twitter.com/share?url=http://yoursite.com/2018/03/23/20180323/"
       onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
        <span class="hidden">Twitter</span>
    </a>
    <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2018/03/23/20180323/"
       onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
        <span class="hidden">Facebook</span>
    </a>
    <a class="icon-google-plus" href="https://plus.google.com/share?url=http://yoursite.com/2018/03/23/20180323/"
       onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;">
        <span class="hidden">Google+</span>
    </a>
</section>
    </footer>
  </article>
  <nav class="pagination" role="pagination">
    
    <span class="page-number">•</span>
    
    <a class="older-posts" href="/2018/03/20/20180320/">
        python学习笔记（一） →
    </a>
    
</nav>
  <div id="comment" class="comments-area">
    <h1 class="title"><a href="#disqus_comments" name="disqus_comments">Comments</a></h1>

    
</div>
</main>


  
<footer class="site-footer">
  
  <div class="inner">
     <section class="copyright">All content copyright <a href="/">Andy</a> &copy; 2014 &bull; All rights reserved.</section>
     <section class="poweredby">Proudly published with <a class="icon-ghost" href="http://zespia.tw/hexo/">Hexo</a></section>
  </div>
</footer>

  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script type="text/javascript" src="/js/jquery.fitvids.js"></script>
<script type="text/javascript" src="/js/index.js"></script>






</body>
</html>
