<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title>tags</title>
      <link href="/2018/03/28/tags/"/>
      <content type="html"><![CDATA[]]></content>
      
      
        <tags>
            
            <tag> tags </tag>
            
        </tags>
      
    </entry>
    
    <entry>
      <title>python学习笔记（二）</title>
      <link href="/2018/03/23/20180323/"/>
      <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a><img src="https://ss1.bdstatic.com/70cFvXSh_Q1YnxGkpoWK1HF6hhy/it/u=3362774969,183177314&amp;fm=27&amp;gp=0.jpg" alt=""></h2><h4 id="今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。"><a href="#今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。" class="headerlink" title="今天我要爬取中国天气网的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。"></a>今天我要爬取<a href="http://www.weather.com.cn/textFC/hb.shtml" target="_blank" rel="noopener">中国天气网</a>的天气，目的是得到全国所有城市的最高温和最低温。嗯，目标明确了以后，我们就来开始干吧。</h4><hr><p>#####首先，我们来看一下我们要爬取的目标网站，做一些准备工作。PS:本地图片现在还不会上传到markdown,很难受。</p><h5 id="第一步-，我们需要以下几个信息"><a href="#第一步-，我们需要以下几个信息" class="headerlink" title="第一步 ，我们需要以下几个信息"></a>第一步 ，我们需要以下几个信息</h5><p>1.得到目标网站：</p><p><pre><br>root_url =  “<a href="http://www.weather.com.cn/textFC/hb.shtml&quot;" target="_blank" rel="noopener">http://www.weather.com.cn/textFC/hb.shtml&quot;</a><br></pre><br>2.得到我们浏览器的请求头：</p><p><pre><br>m_headers = {<br>        “User-Agent”: “Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/64.0.3282.186 Safari/537.36”}<br></pre></p><h4 id="第二步-，现在我们开始写代码"><a href="#第二步-，现在我们开始写代码" class="headerlink" title="第二步 ，现在我们开始写代码"></a>第二步 ，现在我们开始写代码</h4><p>1.请求网站</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">req = urllib.request.Request(url=url, headers=m_headers)</span><br></pre></td></tr></table></figure><p>2.下载网页源码<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">res = urllib.request.urlopen(req)</span><br><span class="line">data = res.read()</span><br><span class="line"># 确定编码格式 utf-8</span><br><span class="line">data = data.decode(&apos;utf-8&apos;)</span><br></pre></td></tr></table></figure></p><p>3.进行网页解析<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 网页解析</span><br><span class="line">soup = BeautifulSoup(data, &apos;html.parser&apos;)</span><br></pre></td></tr></table></figure></p><p>4.通过查询网站源码，F12+…..确定所需要数据在的盒子。<br>注意：这里返回的是一个数组<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 查找里面的带有conMidtab2 的div</span><br><span class="line">conMid_list = soup.find_all(&apos;div&apos;, class_=&apos;conMidtab2&apos;)</span><br></pre></td></tr></table></figure></p><p>5.遍历这个数组，找到我们需要信息所在的行<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 遍历数组查找class_=&apos;conMidtab2&apos;下面的数据</span><br><span class="line">   for x in conMid_list:</span><br><span class="line">       tr_list = x.find_all(&apos;tr&apos;)[2:]  # 使用切片获取第2个数据之后的数据</span><br><span class="line">       province = &quot;&quot;</span><br><span class="line">       # min_tempature = 0</span><br><span class="line">       # max_tempature = 0</span><br><span class="line">       for index, tr in enumerate(tr_list):</span><br><span class="line">           if index == 0:</span><br><span class="line">               td_list = tr.find_all(&apos;td&apos;)</span><br><span class="line">               province = td_list[0].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               city = td_list[1].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               max_tempature = td_list[4].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               min_tempature = td_list[7].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">           else:</span><br><span class="line">               td_list = tr.find_all(&apos;td&apos;)</span><br><span class="line">               city = td_list[0].text.replace(&apos;\n&apos;, &apos;&apos;)</span><br><span class="line">               min_tempature = td_list[6].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br><span class="line">               max_tempature = td_list[3].text.replace(&apos;\n&apos;, &quot;&quot;)</span><br></pre></td></tr></table></figure></p><p>6.创建字典用来存储，<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"># 先在上面全局声明</span><br><span class="line">TEMPATURE_LIST = []</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line">.</span><br><span class="line"># 遍历数组之后，我们在把需要的数据存到字典里面</span><br><span class="line"># 将需要的信息添加到字典</span><br><span class="line">            TEMPATURE_LIST.append(&#123;</span><br><span class="line">                &apos;city&apos;:province + city,</span><br><span class="line">                &apos;min_tempature&apos;: min_tempature,</span><br><span class="line">                &apos;max_tempature&apos;: max_tempature</span><br><span class="line">            &#125;)</span><br></pre></td></tr></table></figure></p><p>7.封装成函数，参数为url<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">def get_temperature(url):</span><br></pre></td></tr></table></figure></p><p>8.水到渠成<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    urls = [&apos;http://www.weather.com.cn/textFC/hb.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/db.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hd.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hz.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/hn.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/xb.shtml&apos;,</span><br><span class="line">            &apos;http://www.weather.com.cn/textFC/xn.shtml&apos;]</span><br><span class="line">    for url in urls:</span><br><span class="line">        get_temperature(url)</span><br><span class="line">        # 睡眠两秒 职业道德</span><br><span class="line">        time.sleep(2)</span><br></pre></td></tr></table></figure></p><p>9.将数据写到json文件里面<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> # 将得到的数据写成json格式</span><br><span class="line">line = json.dumps(TEMPATURE_LIST,ensure_ascii=False)</span><br><span class="line">with open(&apos;temp.json&apos;,&apos;w&apos;) as fp:</span><br><span class="line">    fp.write(line)</span><br></pre></td></tr></table></figure></p><p>10.总结，难点在于寻找所需要信息在的行，并进行提取。顺便说一下，这里需要引入的库。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">import json</span><br><span class="line">import urllib.request</span><br><span class="line">from bs4 import BeautifulSoup</span><br></pre></td></tr></table></figure></p><p>11.这样一运行你就可以得到数据啦。如果有什么疑问的话，可以加我的QQ：2914129301，我也是刚学习python,对爬虫很感兴趣，欢迎交流。</p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>python学习笔记（一）</title>
      <link href="/2018/03/20/20180320/"/>
      <content type="html"><![CDATA[<p><img src="https://ss2.bdstatic.com/70cFvnSh_Q1YnxGkpoWK1HF6hhy/it/u=285340311,2418665357&amp;fm=27&amp;gp=0.jpg" alt=""></p><hr><h4 id="现在开始整理一下自己学习python这门语言的心得和体会，学习python只是单纯的感兴趣，目标是可以学会使用python从网站上面爬一下小说，图片啥的。"><a href="#现在开始整理一下自己学习python这门语言的心得和体会，学习python只是单纯的感兴趣，目标是可以学会使用python从网站上面爬一下小说，图片啥的。" class="headerlink" title="现在开始整理一下自己学习python这门语言的心得和体会，学习python只是单纯的感兴趣，目标是可以学会使用python从网站上面爬一下小说，图片啥的。"></a>现在开始整理一下自己学习python这门语言的心得和体会，学习python只是单纯的感兴趣，目标是可以学会使用python从网站上面爬一下小说，图片啥的。</h4><hr><h5 id="这是刚开始就直接上手的一段代码，目的是爬取我的小伙伴rkk的网站源码，他的点击效果实在是很吸引我。嘿嘿，开始干吧。"><a href="#这是刚开始就直接上手的一段代码，目的是爬取我的小伙伴rkk的网站源码，他的点击效果实在是很吸引我。嘿嘿，开始干吧。" class="headerlink" title="这是刚开始就直接上手的一段代码，目的是爬取我的小伙伴rkk的网站源码，他的点击效果实在是很吸引我。嘿嘿，开始干吧。"></a>这是刚开始就直接上手的一段代码，目的是爬取我的小伙伴rkk的网站源码，他的点击效果实在是很吸引我。嘿嘿，开始干吧。</h5><p>一 ，我们先找到入口即root_url ,在这里我要访问的是凯凯的网站。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 目标网址</span><br><span class="line">root_url = &quot;http://www.rkk9456.com/&quot;</span><br></pre></td></tr></table></figure></p><p>二 ，找到网站入口以后，我们就可以发送请求了。在这里我们要引入一个模块：import urllib.request。代码是这样的。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 请求</span><br><span class="line">request = urllib.request.Request(root_url)</span><br></pre></td></tr></table></figure></p><p>三 ， 发送请求过后，我们就可以到达他的网页了，现在我们把他的网页下载下来。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 下载网页</span><br><span class="line">response = urllib.request.urlopen(request)</span><br></pre></td></tr></table></figure></p><p>四 ，网页下载下来以后，我们就可以打开网页啦，这里要注意的是打开的编码格式。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 打开网页</span><br><span class="line">data = response.read()</span><br><span class="line">data = data.decode(&apos;utf-8&apos;)</span><br></pre></td></tr></table></figure></p><p>五 ，到这里我们就成功啦，现在把下载的网页数据打印出来。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 打印网页源码</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure></p><hr><h3 id="看着这一堆英文字母，我的脑袋是有点大的，嗯，我其实是想把这个数据里面的超链接都提取出来，看看是不是有什么惊喜。"><a href="#看着这一堆英文字母，我的脑袋是有点大的，嗯，我其实是想把这个数据里面的超链接都提取出来，看看是不是有什么惊喜。" class="headerlink" title="看着这一堆英文字母，我的脑袋是有点大的，嗯，我其实是想把这个数据里面的超链接都提取出来，看看是不是有什么惊喜。"></a>看着这一堆英文字母，我的脑袋是有点大的，嗯，我其实是想把这个数据里面的超链接都提取出来，看看是不是有什么惊喜。</h3><hr><h5 id="现在还是原来的项目，只不过我们要搞点复杂的事请。"><a href="#现在还是原来的项目，只不过我们要搞点复杂的事请。" class="headerlink" title="现在还是原来的项目，只不过我们要搞点复杂的事请。"></a>现在还是原来的项目，只不过我们要搞点复杂的事请。</h5><p>一 ，现在我的目标是提取这个数据里面的所有超链接，嗯，目标很明确，开始干吧。首先我要写一个方法，先上个代码。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">def find_all_link(url):</span><br><span class="line">    proto, rest = urllib.request.splittype(url)</span><br><span class="line">    domain = urllib.request.splithost(rest)[0]</span><br><span class="line">    # 读取网页内容</span><br><span class="line">    html = urllib.request.urlopen(url).read()</span><br><span class="line">    # 提取超链接</span><br><span class="line">    a = BeautifulSoup(html).findAll(&apos;a&apos;)</span><br><span class="line">    # 过滤</span><br><span class="line">    a_list = [i.attrs[&apos;href&apos;] for i in a if i.attrs[&apos;href&apos;][0] != &apos;j&apos;]</span><br><span class="line">    # 将形如#comment-text的锚点补全成https://www.ruanyifeng.com/blog/2015/05/co.html,将形如/feed.html补全为https://www.ruanyifeng.com/feed.html</span><br><span class="line">    alist = map(lambda i: proto + &apos;://&apos; + domain + i if i[0] == &apos;/&apos; else url + i if i[0] == &apos;#&apos; else i, a_list)</span><br><span class="line">    return alist</span><br></pre></td></tr></table></figure></p><p>二 ， 上面这个代码是什么意思呢？我看了以后还是可以理解的，我测试了一下，功能是可以实现的，什么？你要我自己写？我刚入门还不会。现在我们写一个主程序入口，嗯就是这样。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    for a in find_all_link(root_url):</span><br><span class="line">        print(a)</span><br></pre></td></tr></table></figure><p>三 ，到这里我就得到凯凯整个网站的信息了，在这里要说一下，凯凯是一个大帅哥，也是一个程序员，总有很多新奇的想法，喜欢钻研各种技术，是我努力地目标。</p><hr><h4 id="最后上凯凯的网站"><a href="#最后上凯凯的网站" class="headerlink" title="最后上凯凯的网站"></a>最后上凯凯的网站</h4><p><a href="http://www.rkk9456.com/" target="_blank" rel="noopener">凯凯的网站</a></p>]]></content>
      
      
    </entry>
    
    <entry>
      <title>常用的网站</title>
      <link href="/2018/03/12/20180312/"/>
      <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a><img src="http://e.hiphotos.baidu.com/image/h%3D300/sign=bf2d1d9c22dda3cc14e4be2031e93905/b03533fa828ba61e5cc84c2c4d34970a304e598b.jpg" alt=""></h2><hr><h3 id="这是一些常用的学习网站"><a href="#这是一些常用的学习网站" class="headerlink" title="这是一些常用的学习网站"></a>这是一些常用的学习网站</h3><p><a href="https://www.csdn.net/" target="_blank" rel="noopener">CSDN</a></p><p><a href="https://www.imooc.com/" target="_blank" rel="noopener">慕课网</a></p><p><a href="http://edu.manew.com/" target="_blank" rel="noopener">蛮牛教育</a></p><p><a href="http://www.51zxw.net/" target="_blank" rel="noopener">51自学网</a></p><p><a href="http://www.sikiedu.com/" target="_blank" rel="noopener">SiKi学院</a></p><p><a href="http://www.taikr.com/" target="_blank" rel="noopener">泰课在线</a></p><p><a href="https://www.shiyanlou.com/" target="_blank" rel="noopener">实验楼</a></p><p><a href="https://tool.lu/" target="_blank" rel="noopener">工具类网站</a></p><hr><h3 id="这里是一些好玩的网站"><a href="#这里是一些好玩的网站" class="headerlink" title="这里是一些好玩的网站"></a>这里是一些好玩的网站</h3><p><a href="http://www.kjson.com/jsoneditor/?f=1" target="_blank" rel="noopener">JSON在线编辑</a></p><p><a href="https://www.bejson.com/" target="_blank" rel="noopener">JSON再线校验</a></p><p><a href="http://www.btrabbit.net/" target="_blank" rel="noopener">BT兔子视频种子</a></p><p><a href="https://pdfconverter.online/cn/" target="_blank" rel="noopener">PDF在线转换器</a></p><p><a href="https://msdn.itellyou.cn/" target="_blank" rel="noopener">MSDN我告诉你</a></p><p><a href="https://www.ico.la/" target="_blank" rel="noopener">在线ICO图标制作</a></p><hr>]]></content>
      
      
    </entry>
    
    <entry>
      <title>欢迎来到我的博客</title>
      <link href="/2018/03/05/20180305/"/>
      <content type="html"><![CDATA[<h2 id=""><a href="#" class="headerlink" title=""></a><img src="http://pic.962.net/up/2016-8/14708834858747664.gif" alt=""></h2>]]></content>
      
      
    </entry>
    
  
  
</search>
